---
name: content-pipeline
description: "通用内容创作流水线：选择工具、生成内容、创作者审核、平台适配"
user-invocable: true
metadata: {"openclaw":{"requires":{"config":["browser.enabled"]},"always":true}}
---

# 通用内容创作流水线

## 用途
当创作者执行 `/write`、`/video` 或自然语言描述创作需求时，编排完整的内容创作流程。

## 支持的入口

- `/write [--tool <名>] <选题/描述>` — 文本类创作
- `/video [--tool <名>] <选题/描述>` — 视频类创作
- 自然语言：如 "帮我写一篇关于 AI 的文章"、"做一个视频讲讲量子计算"

## 流水线步骤

### 步骤 1：理解意图
解析创作者输入，确定：
- **内容类型**：text / video / audio / image
- **选题/描述**：创作者要写什么
- **指定工具**：如果有 `--tool` 参数
- **额外要求**：字数、风格、受众等

### 步骤 2：选择工具
读取 `workspace/config/tools.yaml`：

1. 如果创作者指定了 `--tool <名>`，验证该工具已启用且类型匹配
2. 否则，查找该内容类型的默认工具（`default_for` 包含该类型）
3. 如果没有默认工具，列出该类型所有已启用工具供选择
4. 如果该类型没有已启用的工具，提示创作者先启用：`/tools enable <名>`

### 步骤 3：构造提示词
根据选中的工具，构造适合该工具的提示词：

1. 检查 `workspace/prompts/<工具名>/` 下是否有匹配的模板
2. 如果有，使用模板并填充变量
3. 如果没有，用 Qwen 根据创作者需求生成一个通用提示词
4. 不同工具可能需要不同风格的提示词（如 ChatGPT 喜欢详细指令，Claude 喜欢简洁）

### 步骤 4：调用工具 RPA Skill
根据 tools.yaml 中的 `skill` 字段，调用对应的工具 RPA Skill。

例如：如果选中 chatgpt，则调用 `tool-chatgpt` Skill 的流程。

具体执行：
1. 使用 browser 工具打开对应 profile 的浏览器
2. 导航到工具 URL
3. 检查登录态
4. 输入提示词
5. 等待生成完成
6. 提取结果

### 步骤 5：展示结果，等待审核
将工具生成的内容展示给创作者：

```
✅ <工具名称> 已生成内容：

标题：<标题>
---
<正文摘要，长内容展示前 500 字 + "...">
---
完整内容已保存到 workspace/content/drafts/

请选择：
- 说「满意」或「发布」→ 进入平台适配
- 说修改意见 → 我会让工具修改
- 说「重新生成」→ 重新提交给工具
```

### 步骤 6：修改循环（Human-in-the-loop）
如果创作者提出修改意见：

1. 将修改意见构造为追加提示词
2. 在同一工具会话中追加（RPA 在工具中继续对话）
3. 等待新结果
4. 再次展示，回到步骤 5

循环直到创作者满意。

### 步骤 7：保存草稿
将最终确认的内容保存到 Workspace：
- `workspace/content/drafts/YYYY-MM-DD-<类型>-<slug>.md`
- 包含：工具名、提示词、最终内容、修改历史

### 步骤 8：平台适配（可选）
如果创作者说「发布」或指定了平台：
- 调用 `content-adapt` Skill 将内容适配为各平台格式
- 进入发布流程

## 视频类的特殊处理

视频创作可能涉及多步工具调用，根据视频类型不同：

### 播客/概览式视频（NotebookLM）
1. **文本工具**生成脚本（如 ChatGPT 写脚本）
2. **视频工具**将脚本转为视频（如 NotebookLM 生成视频概览）

### AI 生成视频（可灵/即梦/Sora/Runway）
1. **文本工具**生成视频描述/分镜
2. **视频生成工具**根据描述生成视频片段
3. 可选：多个片段组合

### 数字人口播视频（HeyGen/蝉镜）
1. **文本工具**生成口播脚本
2. **数字人工具**生成口播视频

### 通用视频流程
1. 先用文本类默认工具生成脚本/描述
2. 创作者审核脚本
3. 再用对应视频类工具生成视频
4. 创作者审核视频
5. 进入发布

## 图片类的处理

图片创作通常用于封面/配图/海报：
1. Agent 根据内容主题构造图片描述提示词
2. 调用图片生成工具（DALL-E/Midjourney/通义万相）
3. 创作者选择满意的图片
4. 如需为多平台生成不同尺寸，调用 `cover-generator` Skill

## 音频/TTS 类的处理

音频创作场景：
- **配音/旁白**：文本 → TTS 工具（ElevenLabs/Fish Audio）
- **背景音乐**：描述 → 音乐生成工具（Suno）
- **播客**：脚本 → 多角色 TTS 合成

流程：
1. 确定音频类型和文本内容
2. 调用对应音频工具
3. 创作者试听确认
4. 保存到 workspace/content/media/

## 封面自动生成

在发布流程中，如内容没有封面，自动触发：
1. 根据内容主题和目标平台调用 `cover-generator` Skill
2. 按各平台尺寸要求生成封面
3. 创作者确认后关联到发布内容

## 异常处理

- 工具未登录 → 中断，提示 `/login <工具名>`
- 工具生成超时 → 截图 + 通知创作者
- 工具返回错误 → 截图 + 建议重试或换工具
- 无可用工具 → 提示创作者启用对应类型的工具
